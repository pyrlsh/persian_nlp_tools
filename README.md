# Persian Text Similarity & Summarization Toolkit

## ğŸ“– Overview
This project provides a lightweight toolkit for **Persian Natural Language Processing (NLP)**.  
It includes modules for:

- **Text preprocessing** (normalization, tokenization, stopword removal)
- **TFâ€‘IDF calculation** (Term Frequencyâ€“Inverse Document Frequency)
- **Cosine similarity** between Persian texts
- **Extractive text summarization** using Parsivar

The goal is to make it easy to compare Persian documents and generate concise summaries.

---

## âœ¨ Features

- **Text Preprocessing**
  - Lowercasing and cleaning nonâ€‘Persian characters
  - Normalizing Persian digits (`Û°Û±Û²Û³...Û¹`) into Arabic numerals (`0â€“9`)
  - Tokenization into words and sentences
  - Stopword removal

- **TFâ€‘IDF & Similarity**
  - Compute TF and IDF values across a corpus
  - Generate TFâ€‘IDF vectors
  - Measure cosine similarity between two texts

- **Summarization**
  - Normalize and tokenize text into sentences
  - Extract a percentage of sentences (`ratio`)
  - Limit summary length (`sentence_limit`)
  - Output concise summaries of Persian documents

---

## âš™ï¸ Installation

### Requirements
- Python 3.x
- Libraries:
  - `math`, `re`, `collections`, `typing`
  - [Parsivar](https://github.com/ICTRC/Parsivar)

### Install Dependencies
```bash
pip install -r requirements.txt
```

Example `requirements.txt`:
```txt
parsivar==0.3
```

---

## ğŸš€ Usage

### Text Preprocessing
```python
from persian_text_similarity import TextProcessor

text = "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª."
cleaned = TextProcessor.preprocess_text(text)
tokens = TextProcessor.tokenize(cleaned)
tokens_no_stopwords = TextProcessor.remove_stopwords(tokens)
print(tokens_no_stopwords)
```

### TFâ€‘IDF & Cosine Similarity
```python
from persian_text_similarity import TFIDFCalculator, SimilarityCalculator

corpus = [tokens_no_stopwords, ["Ø³ÛŒÙ†Ù…Ø§", "Ù‡Ù†Ø±", "ØªØ§Ø±ÛŒØ®"]]
idf = TFIDFCalculator.calculate_idf(corpus)
tfidf = TFIDFCalculator.calculate_tf_idf(corpus, idf)

similarity = SimilarityCalculator.cosine_similarity(tfidf[0], tfidf[1])
print(f"Cosine similarity: {similarity}")
```

### Text Summarization
```python
from persian_text_summarizer import TextSummarizationPipeline

input_text = """Ø³ÛŒÙ†Ù…Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù‡Ù†Ø±Ù‡Ø§ÛŒ Ù‚Ø±Ù† Ø¨ÛŒØ³ØªÙ… Ø§Ø³Øª..."""
pipeline = TextSummarizationPipeline(input_text, ratio=0.3, sentence_limit=5)
pipeline.process_and_summarize()
```

---

## ğŸ“ Example

```python
from persian_text_similarity import TextSimilarity

text1 = "ØªØ§Ø±ÛŒØ® Ø³ÛŒÙ†Ù…Ø§: Ø§Ø² Ø¯ÙˆØ±Ø§Ù† ØµØ§Ù…Øª ØªØ§ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ø§Ú©â€ŒØ¨Ø§Ø³ØªØ± Ø§Ù…Ø±ÙˆØ²ÛŒ..."
text2 = "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø³ÛŒÙ†Ù…Ø§: Ø§Ø² ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ ØµØ§Ù…Øª ØªØ§ Ø¨Ù„Ø§Ú©â€ŒØ¨Ø§Ø³ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ø±Ù†..."

similarity_calc = TextSimilarity(text1, text2)
similarity = similarity_calc.process_and_calculate_similarity()

print(f"Cosine similarity between the two texts: {similarity}")
```

---

## ğŸ“‚ File Structure
```
your-project/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ persian_text_similarity.py   # Preprocessing, TF-IDF, similarity
â”œâ”€â”€ persian_text_summarizer.py   # Summarization logic
â”œâ”€â”€ README.md                    # Documentation
â”œâ”€â”€ requirements.txt             # Dependencies
```

---

## ğŸ¤ Contributing
Contributions are welcome!  
1. Fork the repository  
2. Create a new branch for your feature or fix  
3. Add tests to cover your changes  
4. Submit a pull request  

---

## ğŸ“œ License
This project is openâ€‘source under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgements
- [Parsivar](https://github.com/ICTRC/Parsivar) for Persian NLP tools  
- Standard TFâ€‘IDF and cosine similarity methods from information retrieval
